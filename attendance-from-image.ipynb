{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load Neccessary Libraries :","metadata":{}},{"cell_type":"code","source":"import glob\nimport cv2\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nfrom matplotlib.patches import Rectangle\nfrom matplotlib.patches import Circle\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-09-18T03:58:06.697162Z","iopub.execute_input":"2021-09-18T03:58:06.697954Z","iopub.status.idle":"2021-09-18T03:58:06.889963Z","shell.execute_reply.started":"2021-09-18T03:58:06.697841Z","shell.execute_reply":"2021-09-18T03:58:06.889020Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install mtcnn\nimport mtcnn\nfrom mtcnn.mtcnn import MTCNN","metadata":{"execution":{"iopub.status.busy":"2021-09-18T03:58:29.018038Z","iopub.execute_input":"2021-09-18T03:58:29.018357Z","iopub.status.idle":"2021-09-18T03:58:45.996877Z","shell.execute_reply.started":"2021-09-18T03:58:29.018324Z","shell.execute_reply":"2021-09-18T03:58:45.996051Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting mtcnn\n  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n\u001b[K     |████████████████████████████████| 2.3 MB 808 kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: opencv-python>=4.1.0 in /opt/conda/lib/python3.7/site-packages (from mtcnn) (4.5.3.56)\nCollecting keras>=2.0.0\n  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n\u001b[K     |████████████████████████████████| 1.3 MB 42.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from opencv-python>=4.1.0->mtcnn) (1.19.5)\nInstalling collected packages: keras, mtcnn\nSuccessfully installed keras-2.6.0 mtcnn-0.1.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"2021-09-18 03:58:41.154987: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2021-09-18 03:58:41.155099: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nimport torchvision","metadata":{"execution":{"iopub.status.busy":"2021-09-18T03:58:47.266165Z","iopub.execute_input":"2021-09-18T03:58:47.266617Z","iopub.status.idle":"2021-09-18T03:58:48.459099Z","shell.execute_reply.started":"2021-09-18T03:58:47.266585Z","shell.execute_reply":"2021-09-18T03:58:48.458477Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom PIL import Image\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2021-09-18T03:58:59.221620Z","iopub.execute_input":"2021-09-18T03:58:59.222048Z","iopub.status.idle":"2021-09-18T03:58:59.226827Z","shell.execute_reply.started":"2021-09-18T03:58:59.222016Z","shell.execute_reply":"2021-09-18T03:58:59.225722Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Initialising MTCNN for face detection :","metadata":{}},{"cell_type":"code","source":"mtcnn_model = MTCNN()","metadata":{"execution":{"iopub.status.busy":"2021-09-18T03:59:06.370341Z","iopub.execute_input":"2021-09-18T03:59:06.370684Z","iopub.status.idle":"2021-09-18T03:59:06.906733Z","shell.execute_reply.started":"2021-09-18T03:59:06.370652Z","shell.execute_reply":"2021-09-18T03:59:06.905734Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2021-09-18 03:59:06.424276: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-18 03:59:06.427091: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2021-09-18 03:59:06.427127: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n2021-09-18 03:59:06.427156: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (30bf898e87ae): /proc/driver/nvidia/version does not exist\n2021-09-18 03:59:06.427493: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-09-18 03:59:06.427919: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","output_type":"stream"}]},{"cell_type":"code","source":"# scaler = transforms.Scale((224, 224))\nscaler = transforms.Scale((299, 299))   # inceptionv3\nnormalized = transforms.Normalize(mean=[0.485, 0.456, 406],\n                                 std=[0.229, 0.224, 225]) \nto_tensor = transforms.ToTensor()","metadata":{"execution":{"iopub.status.busy":"2021-09-18T03:59:08.927869Z","iopub.execute_input":"2021-09-18T03:59:08.928196Z","iopub.status.idle":"2021-09-18T03:59:08.937349Z","shell.execute_reply.started":"2021-09-18T03:59:08.928165Z","shell.execute_reply":"2021-09-18T03:59:08.936522Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:279: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading Pre-trained Resnet-18 model :","metadata":{}},{"cell_type":"code","source":"resnet = models.resnet18(pretrained=True)\nmodules = list(resnet.children())[:-1]\nresnet_model = nn.Sequential(*modules)\nfor p in resnet_model.parameters():\n    p.requires_grad = False\n# resnet = models.inception_v3(pretrained=True)\n# resnet.eval()","metadata":{"execution":{"iopub.status.busy":"2021-09-18T03:59:14.354595Z","iopub.execute_input":"2021-09-18T03:59:14.355620Z","iopub.status.idle":"2021-09-18T03:59:16.405793Z","shell.execute_reply.started":"2021-09-18T03:59:14.355559Z","shell.execute_reply":"2021-09-18T03:59:16.405075Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/44.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8e75389082644779e45f4d3334b2973"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Turning off Dropout & BatchNormalization layers for model evaluation :","metadata":{}},{"cell_type":"code","source":"resnet_model.eval()","metadata":{"execution":{"iopub.status.busy":"2021-09-18T03:59:41.523630Z","iopub.execute_input":"2021-09-18T03:59:41.523943Z","iopub.status.idle":"2021-09-18T03:59:41.533913Z","shell.execute_reply.started":"2021-09-18T03:59:41.523914Z","shell.execute_reply":"2021-09-18T03:59:41.533031Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU(inplace=True)\n  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (5): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (6): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (7): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Loading Image Paths :","metadata":{}},{"cell_type":"code","source":"img_path = sorted(glob.glob('../input/face-recognition-attendance/trainset - Copy/*/*/*.jpg'))\nimg_path_2 = sorted(glob.glob('../input/face-recognition-attendance/trainset - Copy/*/*'))","metadata":{"execution":{"iopub.status.busy":"2021-09-18T03:59:46.663409Z","iopub.execute_input":"2021-09-18T03:59:46.664617Z","iopub.status.idle":"2021-09-18T03:59:51.385591Z","shell.execute_reply.started":"2021-09-18T03:59:46.664557Z","shell.execute_reply":"2021-09-18T03:59:51.384337Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Image preproccessing :","metadata":{}},{"cell_type":"code","source":"multi_face_list = []\ndef img_preproccessing(path):\n    img_array = cv2.imread(path)\n    img_array = cv2.resize(img_array, dsize=(350,350), interpolation=cv2.INTER_CUBIC)\n    img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n    face = mtcnn_model.detect_faces(img_array)\n    if len(face) == 1:\n        x,y,w,h = face[0]['box']\n        new_img_array = img_array[y:y+h, x:x+w]\n        img = Image.fromarray(np.uint8(new_img_array)).convert('RGB')\n        t_img = Variable(normalized(to_tensor(scaler(img))).unsqueeze(0))\n        return t_img\n    elif len(face) > 1:\n        for f in range(len(face)):\n            x,y,w,h = face[f]['box']\n            new_img_array = img_array[y:y+h, x:x+w]\n            img = Image.fromarray(np.uint8(new_img_array)).convert('RGB')\n            t_img = Variable(normalized(to_tensor(scaler(img))).unsqueeze(0))\n            multi_face_list.append(t_img)\n        return multi_face_list, face\n    else:\n        print(\"No faces found !....\")","metadata":{"execution":{"iopub.status.busy":"2021-09-18T03:59:53.691903Z","iopub.execute_input":"2021-09-18T03:59:53.692184Z","iopub.status.idle":"2021-09-18T03:59:53.704043Z","shell.execute_reply.started":"2021-09-18T03:59:53.692155Z","shell.execute_reply":"2021-09-18T03:59:53.702789Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Manually Assigning labels to the respective image path :","metadata":{}},{"cell_type":"code","source":"label_counter = 0\nmain_label = []\nmain_path = []\nfor path in img_path_2:\n    for img in sorted(glob.glob(path+'/*')):\n        main_path.append(img)\n        main_label.append(label_counter)\n    label_counter+=1","metadata":{"execution":{"iopub.status.busy":"2021-09-18T03:59:56.071646Z","iopub.execute_input":"2021-09-18T03:59:56.072225Z","iopub.status.idle":"2021-09-18T03:59:56.580989Z","shell.execute_reply.started":"2021-09-18T03:59:56.072171Z","shell.execute_reply":"2021-09-18T03:59:56.579794Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata = pd.DataFrame()\ndata['paths'] = pd.Series(main_path)\ndata['labels'] = pd.Series(main_label)\ndata.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T03:59:57.653655Z","iopub.execute_input":"2021-09-18T03:59:57.654297Z","iopub.status.idle":"2021-09-18T03:59:57.689603Z","shell.execute_reply.started":"2021-09-18T03:59:57.654226Z","shell.execute_reply":"2021-09-18T03:59:57.688646Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                               paths  labels\n0  ../input/face-recognition-attendance/trainset ...       0\n1  ../input/face-recognition-attendance/trainset ...       0\n2  ../input/face-recognition-attendance/trainset ...       0\n3  ../input/face-recognition-attendance/trainset ...       1\n4  ../input/face-recognition-attendance/trainset ...       1\n5  ../input/face-recognition-attendance/trainset ...       1\n6  ../input/face-recognition-attendance/trainset ...       2\n7  ../input/face-recognition-attendance/trainset ...       2\n8  ../input/face-recognition-attendance/trainset ...       2\n9  ../input/face-recognition-attendance/trainset ...       3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paths</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## One-Hot_Encodding :","metadata":{}},{"cell_type":"code","source":"dummy = pd.get_dummies(data['labels'])\ndummy.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-18T04:00:00.078825Z","iopub.execute_input":"2021-09-18T04:00:00.079149Z","iopub.status.idle":"2021-09-18T04:00:00.098353Z","shell.execute_reply.started":"2021-09-18T04:00:00.079120Z","shell.execute_reply":"2021-09-18T04:00:00.097437Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(4419, 1012)"},"metadata":{}}]},{"cell_type":"code","source":"tensor_target = torch.tensor(dummy.values).view(dummy.shape[0], dummy.shape[1])\ntensor_target.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-18T04:00:01.270892Z","iopub.execute_input":"2021-09-18T04:00:01.271188Z","iopub.status.idle":"2021-09-18T04:00:01.279887Z","shell.execute_reply.started":"2021-09-18T04:00:01.271156Z","shell.execute_reply":"2021-09-18T04:00:01.279180Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"torch.Size([4419, 1012])"},"metadata":{}}]},{"cell_type":"markdown","source":"## Image Embedding using Resnet18 model :","metadata":{}},{"cell_type":"code","source":"multiface_path = []\ndef get_vector(path):\n    img_array = cv2.imread(path)\n    img_array = cv2.resize(img_array, dsize=(350, 350), interpolation=cv2.INTER_CUBIC)\n    img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n    face = mtcnn_model.detect_faces(img_array)\n    if len(face) == 1:\n        x,y,w,h = face[0]['box']\n        new_img_array = img_array[y:y+h, x:x+w]\n    #     img = Image.open(path)\n        img = Image.fromarray(np.uint8(new_img_array)).convert('RGB')\n        t_img = Variable(normalized(to_tensor(scaler(img))).unsqueeze(0))\n        img_vec = resnet_model(t_img)\n        img_vec = img_vec.resize(1,512)\n\n        return img_vec, len(face)\n    elif len(face) > 1:\n        multiface_path.append(path)\n        return torch.zeros(1,512), len(face)\n    else :\n        return torch.zeros(1,512), len(face)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T04:00:02.485121Z","iopub.execute_input":"2021-09-18T04:00:02.486300Z","iopub.status.idle":"2021-09-18T04:00:02.496966Z","shell.execute_reply.started":"2021-09-18T04:00:02.486240Z","shell.execute_reply":"2021-09-18T04:00:02.495374Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Converting Image tensor list to tensor for model training :","metadata":{}},{"cell_type":"code","source":"tensor_vecs = torch.zeros(len(data['paths']), 1, 512)\nfaces = []\nfor i in range(len(data['paths'])):\n    tensor_vecs[i], face = get_vector(data[\"paths\"][i])\n    faces.append(face)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T04:00:04.803868Z","iopub.execute_input":"2021-09-18T04:00:04.804203Z","iopub.status.idle":"2021-09-18T04:47:45.949696Z","shell.execute_reply.started":"2021-09-18T04:00:04.804173Z","shell.execute_reply":"2021-09-18T04:47:45.948739Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"2021-09-18 04:00:04.952116: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n2021-09-18 04:00:04.966117: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n/opt/conda/lib/python3.7/site-packages/torch/tensor.py:447: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n","output_type":"stream"}]},{"cell_type":"code","source":"len(faces)    # 3129","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:04:05.208140Z","iopub.execute_input":"2021-09-18T05:04:05.208591Z","iopub.status.idle":"2021-09-18T05:04:05.218158Z","shell.execute_reply.started":"2021-09-18T05:04:05.208552Z","shell.execute_reply":"2021-09-18T05:04:05.217142Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"4419"},"metadata":{}}]},{"cell_type":"code","source":"data['faces'] = pd.Series(faces)\ndata.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:04:09.424165Z","iopub.execute_input":"2021-09-18T05:04:09.425117Z","iopub.status.idle":"2021-09-18T05:04:09.442779Z","shell.execute_reply.started":"2021-09-18T05:04:09.425069Z","shell.execute_reply":"2021-09-18T05:04:09.441496Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"                                               paths  labels  faces\n0  ../input/face-recognition-attendance/trainset ...       0      1\n1  ../input/face-recognition-attendance/trainset ...       0      1\n2  ../input/face-recognition-attendance/trainset ...       0      1\n3  ../input/face-recognition-attendance/trainset ...       1      2\n4  ../input/face-recognition-attendance/trainset ...       1      1\n5  ../input/face-recognition-attendance/trainset ...       1      1\n6  ../input/face-recognition-attendance/trainset ...       2      7\n7  ../input/face-recognition-attendance/trainset ...       2      7\n8  ../input/face-recognition-attendance/trainset ...       2      1\n9  ../input/face-recognition-attendance/trainset ...       3      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paths</th>\n      <th>labels</th>\n      <th>faces</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>2</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>2</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>../input/face-recognition-attendance/trainset ...</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Extracting dataset with one face detected for training purpose :","metadata":{}},{"cell_type":"code","source":"final_data = data.loc[data['faces'] == 1]\nfinal_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:04:12.956900Z","iopub.execute_input":"2021-09-18T05:04:12.957202Z","iopub.status.idle":"2021-09-18T05:04:12.970424Z","shell.execute_reply.started":"2021-09-18T05:04:12.957171Z","shell.execute_reply":"2021-09-18T05:04:12.969322Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(4019, 3)"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Index for the image tensor with only one face detected :","metadata":{}},{"cell_type":"code","source":"index = np.where(data['faces'] == 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:04:14.860828Z","iopub.execute_input":"2021-09-18T05:04:14.861144Z","iopub.status.idle":"2021-09-18T05:04:14.866946Z","shell.execute_reply.started":"2021-09-18T05:04:14.861112Z","shell.execute_reply":"2021-09-18T05:04:14.866148Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"len(index[0])","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:04:16.461729Z","iopub.execute_input":"2021-09-18T05:04:16.462273Z","iopub.status.idle":"2021-09-18T05:04:16.469040Z","shell.execute_reply.started":"2021-09-18T05:04:16.462236Z","shell.execute_reply":"2021-09-18T05:04:16.468313Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"4019"},"metadata":{}}]},{"cell_type":"code","source":"final_tensor = tensor_vecs[index]\nfinal_tensor.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:04:19.206161Z","iopub.execute_input":"2021-09-18T05:04:19.206600Z","iopub.status.idle":"2021-09-18T05:04:19.221832Z","shell.execute_reply.started":"2021-09-18T05:04:19.206568Z","shell.execute_reply":"2021-09-18T05:04:19.220811Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"torch.Size([4019, 1, 512])"},"metadata":{}}]},{"cell_type":"code","source":"final_target = tensor_target[index].view(4019,1012)\nfinal_target.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:04:26.716750Z","iopub.execute_input":"2021-09-18T05:04:26.717159Z","iopub.status.idle":"2021-09-18T05:04:26.740479Z","shell.execute_reply.started":"2021-09-18T05:04:26.717130Z","shell.execute_reply":"2021-09-18T05:04:26.739644Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"torch.Size([4019, 1012])"},"metadata":{}}]},{"cell_type":"code","source":"torch.argmax(final_target,dim=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:04:28.802960Z","iopub.execute_input":"2021-09-18T05:04:28.803403Z","iopub.status.idle":"2021-09-18T05:04:28.823919Z","shell.execute_reply.started":"2021-09-18T05:04:28.803374Z","shell.execute_reply":"2021-09-18T05:04:28.823079Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"tensor([   0,    0,    0,  ..., 1010, 1011, 1011])"},"metadata":{}}]},{"cell_type":"markdown","source":"### Image path which have multiple faces :","metadata":{}},{"cell_type":"code","source":"len(multiface_path)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:04:31.471295Z","iopub.execute_input":"2021-09-18T05:04:31.471609Z","iopub.status.idle":"2021-09-18T05:04:31.477500Z","shell.execute_reply.started":"2021-09-18T05:04:31.471576Z","shell.execute_reply":"2021-09-18T05:04:31.476812Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"398"},"metadata":{}}]},{"cell_type":"markdown","source":"## Net model for Image tensor training :","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(512, 1024)\n        self.fc2 = nn.Linear(1024, 2048)\n        self.fc3 = nn.Linear(2048, 1024)\n        self.fc4 = nn.Linear(1024, 1012)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n#         return F.log_softmax(x, dim=1)\n        return F.log_softmax(x)\n\nnet = Net()","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:04:34.442652Z","iopub.execute_input":"2021-09-18T05:04:34.443737Z","iopub.status.idle":"2021-09-18T05:04:34.496637Z","shell.execute_reply.started":"2021-09-18T05:04:34.443676Z","shell.execute_reply":"2021-09-18T05:04:34.495717Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### Turning off the dropout & batchnormalization layers for model evaluation :","metadata":{}},{"cell_type":"code","source":"net.eval()","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:04:36.857935Z","iopub.execute_input":"2021-09-18T05:04:36.858288Z","iopub.status.idle":"2021-09-18T05:04:36.865389Z","shell.execute_reply.started":"2021-09-18T05:04:36.858253Z","shell.execute_reply":"2021-09-18T05:04:36.864408Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"Net(\n  (fc1): Linear(in_features=512, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=2048, bias=True)\n  (fc3): Linear(in_features=2048, out_features=1024, bias=True)\n  (fc4): Linear(in_features=1024, out_features=1012, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Optimization & Loss Initialization :","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\nloss_function = nn.BCEWithLogitsLoss()\n# loss_function = nn.()\noptimizer = optim.Adam(net.parameters(), lr = 0.0015)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:04:40.647023Z","iopub.execute_input":"2021-09-18T05:04:40.647325Z","iopub.status.idle":"2021-09-18T05:04:40.655576Z","shell.execute_reply.started":"2021-09-18T05:04:40.647296Z","shell.execute_reply":"2021-09-18T05:04:40.654243Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## Model Training :","metadata":{}},{"cell_type":"code","source":"for epoch in range(150):\n    net.zero_grad()\n    output = net(torch.tensor(final_tensor.view(-1,512), dtype = torch.float32))\n#     loss = F.nll_loss(output, torch.tensor([y[i]]))\n#     loss = F.nll_loss(output, class_list)\n    loss = loss_function(output, final_target.float())\n    loss.backward()\n    optimizer.step()\n    print(\"epoch:\", epoch,\"   \"  \"Loss :\",loss)\n    print(\"============================================================\")","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:04:48.371263Z","iopub.execute_input":"2021-09-18T05:04:48.372194Z","iopub.status.idle":"2021-09-18T05:08:46.008352Z","shell.execute_reply.started":"2021-09-18T05:04:48.372136Z","shell.execute_reply":"2021-09-18T05:08:46.007160Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  This is separate from the ipykernel package so we can avoid doing imports until\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n  app.launch_new_instance()\n","output_type":"stream"},{"name":"stdout","text":"epoch: 0    Loss : tensor(0.0078, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 1    Loss : tensor(0.0078, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 2    Loss : tensor(0.0078, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 3    Loss : tensor(0.0077, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 4    Loss : tensor(0.0078, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 5    Loss : tensor(0.0078, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 6    Loss : tensor(0.0077, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 7    Loss : tensor(0.0077, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 8    Loss : tensor(0.0077, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 9    Loss : tensor(0.0076, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 10    Loss : tensor(0.0076, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 11    Loss : tensor(0.0075, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 12    Loss : tensor(0.0075, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 13    Loss : tensor(0.0074, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 14    Loss : tensor(0.0075, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 15    Loss : tensor(0.0075, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 16    Loss : tensor(0.0073, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 17    Loss : tensor(0.0073, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 18    Loss : tensor(0.0073, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 19    Loss : tensor(0.0071, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 20    Loss : tensor(0.0071, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 21    Loss : tensor(0.0071, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 22    Loss : tensor(0.0070, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 23    Loss : tensor(0.0069, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 24    Loss : tensor(0.0068, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 25    Loss : tensor(0.0067, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 26    Loss : tensor(0.0067, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 27    Loss : tensor(0.0070, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 28    Loss : tensor(0.0072, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 29    Loss : tensor(0.0068, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 30    Loss : tensor(0.0067, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 31    Loss : tensor(0.0066, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 32    Loss : tensor(0.0067, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 33    Loss : tensor(0.0066, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 34    Loss : tensor(0.0065, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 35    Loss : tensor(0.0065, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 36    Loss : tensor(0.0064, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 37    Loss : tensor(0.0062, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 38    Loss : tensor(0.0062, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 39    Loss : tensor(0.0061, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 40    Loss : tensor(0.0060, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 41    Loss : tensor(0.0059, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 42    Loss : tensor(0.0058, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 43    Loss : tensor(0.0058, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 44    Loss : tensor(0.0058, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 45    Loss : tensor(0.0061, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 46    Loss : tensor(0.0058, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 47    Loss : tensor(0.0055, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 48    Loss : tensor(0.0056, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 49    Loss : tensor(0.0053, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 50    Loss : tensor(0.0054, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 51    Loss : tensor(0.0052, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 52    Loss : tensor(0.0052, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 53    Loss : tensor(0.0050, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 54    Loss : tensor(0.0049, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 55    Loss : tensor(0.0048, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 56    Loss : tensor(0.0047, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 57    Loss : tensor(0.0047, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 58    Loss : tensor(0.0049, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 59    Loss : tensor(0.0056, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 60    Loss : tensor(0.0052, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 61    Loss : tensor(0.0050, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 62    Loss : tensor(0.0048, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 63    Loss : tensor(0.0047, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 64    Loss : tensor(0.0045, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 65    Loss : tensor(0.0045, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 66    Loss : tensor(0.0044, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 67    Loss : tensor(0.0043, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 68    Loss : tensor(0.0042, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 69    Loss : tensor(0.0041, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 70    Loss : tensor(0.0040, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 71    Loss : tensor(0.0038, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 72    Loss : tensor(0.0037, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 73    Loss : tensor(0.0035, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 74    Loss : tensor(0.0035, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 75    Loss : tensor(0.0034, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 76    Loss : tensor(0.0033, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 77    Loss : tensor(0.0032, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 78    Loss : tensor(0.0034, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 79    Loss : tensor(0.0044, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 80    Loss : tensor(0.0042, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 81    Loss : tensor(0.0045, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 82    Loss : tensor(0.0040, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 83    Loss : tensor(0.0039, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 84    Loss : tensor(0.0036, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 85    Loss : tensor(0.0035, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 86    Loss : tensor(0.0036, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 87    Loss : tensor(0.0034, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 88    Loss : tensor(0.0033, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 89    Loss : tensor(0.0033, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 90    Loss : tensor(0.0031, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 91    Loss : tensor(0.0030, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 92    Loss : tensor(0.0029, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 93    Loss : tensor(0.0027, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 94    Loss : tensor(0.0026, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 95    Loss : tensor(0.0025, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 96    Loss : tensor(0.0024, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 97    Loss : tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 98    Loss : tensor(0.0022, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 99    Loss : tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 100    Loss : tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 101    Loss : tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 102    Loss : tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 103    Loss : tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 104    Loss : tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 105    Loss : tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 106    Loss : tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 107    Loss : tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 108    Loss : tensor(0.0026, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 109    Loss : tensor(0.0037, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 110    Loss : tensor(0.0035, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 111    Loss : tensor(0.0040, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 112    Loss : tensor(0.0029, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 113    Loss : tensor(0.0028, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 114    Loss : tensor(0.0030, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 115    Loss : tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 116    Loss : tensor(0.0024, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 117    Loss : tensor(0.0025, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 118    Loss : tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 119    Loss : tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 120    Loss : tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 121    Loss : tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 122    Loss : tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 123    Loss : tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 124    Loss : tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 125    Loss : tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 126    Loss : tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 127    Loss : tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 128    Loss : tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 129    Loss : tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 130    Loss : tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 131    Loss : tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 132    Loss : tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 133    Loss : tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 134    Loss : tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 135    Loss : tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 136    Loss : tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 137    Loss : tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 138    Loss : tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 139    Loss : tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 140    Loss : tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 141    Loss : tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 142    Loss : tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 143    Loss : tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 144    Loss : tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 145    Loss : tensor(0.0008, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 146    Loss : tensor(0.0008, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 147    Loss : tensor(0.0008, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 148    Loss : tensor(0.0008, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\nepoch: 149    Loss : tensor(0.0008, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n============================================================\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model Prediction :","metadata":{}},{"cell_type":"code","source":"pred = net(torch.tensor(final_tensor.view(-1,512), dtype = torch.float32))","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:14:53.965088Z","iopub.execute_input":"2021-09-18T05:14:53.965466Z","iopub.status.idle":"2021-09-18T05:14:54.362780Z","shell.execute_reply.started":"2021-09-18T05:14:53.965417Z","shell.execute_reply":"2021-09-18T05:14:54.360233Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \"\"\"Entry point for launching an IPython kernel.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n  app.launch_new_instance()\n","output_type":"stream"}]},{"cell_type":"code","source":"p = net(torch.tensor(final_tensor[1].view(-1,512), dtype = torch.float32))\np.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:14:56.361363Z","iopub.execute_input":"2021-09-18T05:14:56.361728Z","iopub.status.idle":"2021-09-18T05:14:56.378881Z","shell.execute_reply.started":"2021-09-18T05:14:56.361692Z","shell.execute_reply":"2021-09-18T05:14:56.376696Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \"\"\"Entry point for launching an IPython kernel.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n  app.launch_new_instance()\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 1012])"},"metadata":{}}]},{"cell_type":"code","source":"pred_classes = torch.argmax(pred, dim=1)\npred_classes.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:15:04.195394Z","iopub.execute_input":"2021-09-18T05:15:04.195859Z","iopub.status.idle":"2021-09-18T05:15:04.214285Z","shell.execute_reply.started":"2021-09-18T05:15:04.195814Z","shell.execute_reply":"2021-09-18T05:15:04.213420Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"torch.Size([4019])"},"metadata":{}}]},{"cell_type":"code","source":"y_true = torch.argmax(final_target, dim=1)\ny_true.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:15:08.567789Z","iopub.execute_input":"2021-09-18T05:15:08.568825Z","iopub.status.idle":"2021-09-18T05:15:08.580749Z","shell.execute_reply.started":"2021-09-18T05:15:08.568764Z","shell.execute_reply":"2021-09-18T05:15:08.580052Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"torch.Size([4019])"},"metadata":{}}]},{"cell_type":"markdown","source":"## Accuracy Check :","metadata":{}},{"cell_type":"code","source":"np.mean( y_true.numpy() == pred_classes.numpy() )","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:15:21.064431Z","iopub.execute_input":"2021-09-18T05:15:21.065381Z","iopub.status.idle":"2021-09-18T05:15:21.073927Z","shell.execute_reply.started":"2021-09-18T05:15:21.065335Z","shell.execute_reply":"2021-09-18T05:15:21.072849Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"0.9965165464045782"},"metadata":{}}]},{"cell_type":"markdown","source":"## Testing Prediction :","metadata":{}},{"cell_type":"code","source":"print(\"Image's True Class :\", y_true[5].numpy())\nprint(\"Image's True Class :\", pred_classes[5].numpy())","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:32:08.942091Z","iopub.execute_input":"2021-09-18T05:32:08.942380Z","iopub.status.idle":"2021-09-18T05:32:08.949093Z","shell.execute_reply.started":"2021-09-18T05:32:08.942349Z","shell.execute_reply":"2021-09-18T05:32:08.947617Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Image's True Class : 2\nImage's True Class : 2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Confusion Matrix :","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true, pred_classes)","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:30:00.446154Z","iopub.status.idle":"2021-09-18T05:30:00.446945Z","shell.execute_reply.started":"2021-09-18T05:30:00.446745Z","shell.execute_reply":"2021-09-18T05:30:00.446767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm","metadata":{"execution":{"iopub.status.busy":"2021-09-18T05:30:05.122078Z","iopub.execute_input":"2021-09-18T05:30:05.122381Z","iopub.status.idle":"2021-09-18T05:30:05.128983Z","shell.execute_reply.started":"2021-09-18T05:30:05.122348Z","shell.execute_reply":"2021-09-18T05:30:05.128127Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"array([[3, 0, 0, ..., 0, 0, 0],\n       [0, 2, 0, ..., 0, 0, 0],\n       [0, 0, 1, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 5, 0, 0],\n       [0, 0, 0, ..., 0, 5, 0],\n       [0, 0, 0, ..., 0, 0, 2]])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}